# -*- coding: utf-8 -*-
import cv2
import time
import threading
import asyncio
import json
import numpy as np
import mediapipe as mp
import websockets

from mediapipe.tasks import python
from mediapipe.tasks.python import vision

# ---------------------------
# ì„¤ì •ê°’ (ì—¬ê¸°ë§Œ ì¡°ì ˆí•˜ë©´ ë¨)
# ---------------------------
CAM_INDEX = 1              # ë³´í†µ 0=ì•„ì´í°(ì—°ì†ì„±), 1=ë§¥ë¶ ë‚´ì¥
BLINK_TH = 0.20            # ì‘ì„ìˆ˜ë¡ ëœ ë¯¼ê°(ì˜¤í´ë¦­â†“), í´ìˆ˜ë¡ ë” ë¯¼ê°(ì¸ì‹â†‘)
BLINK_COOLDOWN_SEC = 0.35  # ì—°ì† ë¸”ë§í¬ ì¤‘ë³µ ì¹´ìš´íŠ¸ ë°©ì§€

# WebSocket í´ë¼ì´ì–¸íŠ¸ë“¤ì„ ê´€ë¦¬í•˜ê¸° ìœ„í•œ ì „ì—­ ì„¸íŠ¸
WS_CLIENTS = set()
WS_HOST = "localhost"
WS_PORT = 8765


async def _ws_handler(websocket):
    """í”„ë¡ íŠ¸ì—”ë“œ(React)ê°€ ì ‘ì†í•˜ëŠ” WebSocket í•¸ë“¤ëŸ¬."""
    WS_CLIENTS.add(websocket)
    try:
        async for _ in websocket:
            # ì§€ê¸ˆì€ ì„œë²„ì—ì„œ ë³´ë‚´ê¸°ë§Œ í•˜ê³ , í´ë¼ì´ì–¸íŠ¸ ë©”ì‹œì§€ëŠ” ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
            pass
    finally:
        WS_CLIENTS.discard(websocket)


def start_ws_server_in_background():
    """ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ WebSocket ì„œë²„ ì‹¤í–‰."""

    async def _run():
        async with websockets.serve(_ws_handler, WS_HOST, WS_PORT):
            print(f"ğŸŒ WebSocket ì„œë²„ ì‹œì‘: ws://{WS_HOST}:{WS_PORT}")
            await asyncio.Future()  # ì„œë²„ë¥¼ ê³„ì† ìœ ì§€

    def _thread_target():
        asyncio.run(_run())

    t = threading.Thread(target=_thread_target, daemon=True)
    t.start()


def _broadcast_to_clients(message: str):
    """ëª¨ë“  WebSocket í´ë¼ì´ì–¸íŠ¸ì— ë¬¸ìì—´ ë©”ì‹œì§€ë¥¼ ì „ì†¡."""

    async def _broadcast():
        if not WS_CLIENTS:
            return
        await asyncio.gather(
            *[ws.send(message) for ws in list(WS_CLIENTS)],
            return_exceptions=True,
        )

    # core ë£¨í”„ëŠ” asyncioë¥¼ ì“°ì§€ ì•Šìœ¼ë¯€ë¡œ, ë§¤ë²ˆ ê°„ë‹¨íˆ run
    try:
        asyncio.run(_broadcast())
    except RuntimeError:
        # ì´ë¯¸ ë‹¤ë¥¸ ì´ë²¤íŠ¸ ë£¨í”„ê°€ ëŒê³  ìˆë‹¤ë©´ ì—¬ê¸°ì„œëŠ” ë¬´ì‹œ
        pass


def notify_blink_to_clients():
    """ë¸”ë§í¬ê°€ ê°ì§€ë˜ì—ˆì„ ë•Œ 'blink' íƒ€ì… ì´ë²¤íŠ¸ ì „ì†¡."""
    msg = json.dumps({"type": "blink"})
    _broadcast_to_clients(msg)


def send_gaze_to_clients(norm_x: float, norm_y: float):
    """0~1 ë²”ìœ„ì˜ ì‹œì„  ì¢Œí‘œë¥¼ í”„ë¡ íŠ¸ë¡œ ì „ì†¡."""
    msg = json.dumps(
        {
            "type": "gaze",
            "x": float(norm_x),
            "y": float(norm_y),
        }
    )
    _broadcast_to_clients(msg)


# FaceLandmarker(=FaceMesh ê³„ì—´)ì—ì„œ ë§ì´ ì“°ëŠ” ëˆˆ ëœë“œë§ˆí¬ ì¸ë±ìŠ¤
LEFT_EYE = {"outer": 33, "inner": 133, "top": 159, "bottom": 145}
RIGHT_EYE = {"outer": 362, "inner": 263, "top": 386, "bottom": 374}

def dist(a, b):
    return np.linalg.norm(np.array(a) - np.array(b))

def eye_ratio(landmarks, eye, w, h):
    """
    EAR ë¹„ìŠ·í•œ ê°’ = ì„¸ë¡œ/ê°€ë¡œ
    landmarksëŠ” normalized(0~1)ì´ë¯€ë¡œ í”½ì…€ë¡œ ë³€í™˜í•´ì„œ ê±°ë¦¬ ê³„ì‚°
    """
    def pt(idx):
        p = landmarks[idx]
        return (p.x * w, p.y * h)

    top = pt(eye["top"])
    bottom = pt(eye["bottom"])
    outer = pt(eye["outer"])
    inner = pt(eye["inner"])

    v = dist(top, bottom)
    hor = dist(outer, inner)
    return v / (hor + 1e-6)

def main():
    # WebSocket ì„œë²„ë¥¼ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹œì‘
    start_ws_server_in_background()

    # 1) ì¹´ë©”ë¼ ì—´ê¸°
    cap = cv2.VideoCapture(CAM_INDEX)
    if not cap.isOpened():
        print("âŒ ì¹´ë©”ë¼ ì˜¤í”ˆ ì‹¤íŒ¨.")
        print("   - CAM_INDEXë¥¼ 0/1/2ë¡œ ë°”ê¿”ë³´ê±°ë‚˜")
        print("   - macOS ì¹´ë©”ë¼ ê¶Œí•œ(í„°ë¯¸ë„/íŒŒì´ì¬/VSCode) í™•ì¸í•´ì¤˜.")
        return

    # 2) FaceLandmarker(Task) ë¡œë“œ
    # ê°™ì€ í´ë”ì— face_landmarker.task íŒŒì¼ì´ ìˆì–´ì•¼ í•¨
    base_options = python.BaseOptions(model_asset_path="face_landmarker.task")
    options = vision.FaceLandmarkerOptions(
        base_options=base_options,
        running_mode=vision.RunningMode.VIDEO,
        num_faces=1,
        output_face_blendshapes=False,
        output_facial_transformation_matrixes=False,
    )
    landmarker = vision.FaceLandmarker.create_from_options(options)

    blink_count = 0
    last_blink_time = 0.0
    prev_time = time.time()

    print("âœ… ì‹œì‘! OpenCV ì°½ì—ì„œ q ë˜ëŠ” ESCë¡œ ì¢…ë£Œ")

    while True:
        ok, frame = cap.read()
        if not ok:
            print("âŒ í”„ë ˆì„ ì½ê¸° ì‹¤íŒ¨")
            break

        # ê±°ìš¸ ëª¨ë“œ
        frame = cv2.flip(frame, 1)
        h, w = frame.shape[:2]

        # BGR -> RGB
        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)

        # 3) mediapipe Image ë§Œë“¤ê³  ì¶”ë¡ 
        ts_ms = int(time.time() * 1000)
        mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=rgb)
        res = landmarker.detect_for_video(mp_image, ts_ms)

        # FPS ê³„ì‚°
        now = time.time()
        fps = 1.0 / max(now - prev_time, 1e-6)
        prev_time = now

        status = "NO FACE"
        ratio = None

        if res.face_landmarks and len(res.face_landmarks) > 0:
            lm = res.face_landmarks[0]

            r1 = eye_ratio(lm, LEFT_EYE, w, h)
            r2 = eye_ratio(lm, RIGHT_EYE, w, h)
            ratio = (r1 + r2) / 2.0

            status = f"EAR-like: {ratio:.3f}"

            # ê°„ë‹¨í•œ ì‹œì„  ì¢Œí‘œ: ì–‘ìª½ ëˆˆ ì¤‘ì•™ì˜ ì¤‘ê°„ì§€ì ì„ ì‚¬ìš© (0~1 ì •ê·œí™”)
            left_inner = lm[LEFT_EYE["inner"]]
            right_inner = lm[RIGHT_EYE["inner"]]
            gaze_x = (left_inner.x + right_inner.x) / 2.0
            gaze_y = (left_inner.y + right_inner.y) / 2.0

            send_gaze_to_clients(gaze_x, gaze_y)

            # 4) ë¸”ë§í¬ ê°ì§€(ì¿¨ë‹¤ìš´ í¬í•¨)
            if ratio < BLINK_TH and (now - last_blink_time) > BLINK_COOLDOWN_SEC:
                blink_count += 1
                last_blink_time = now
                status += "  BLINK!"

                # ëˆˆ ê¹œë¹¡ì„ ì´ë²¤íŠ¸ë¥¼ í”„ë¡ íŠ¸ì—”ë“œ(React)ë¡œ ì „ì†¡
                notify_blink_to_clients()

            # 5) ëˆˆ ì  í‘œì‹œ(ë””ë²„ê¹…)
            for idx in [
                LEFT_EYE["outer"], LEFT_EYE["inner"], LEFT_EYE["top"], LEFT_EYE["bottom"],
                RIGHT_EYE["outer"], RIGHT_EYE["inner"], RIGHT_EYE["top"], RIGHT_EYE["bottom"],
            ]:
                p = lm[idx]
                cx, cy = int(p.x * w), int(p.y * h)
                cv2.circle(frame, (cx, cy), 3, (0, 255, 0), -1)

        # HUD í‘œì‹œ
        cv2.putText(frame, f"FPS: {fps:.1f}", (20, 40),
                    cv2.FONT_HERSHEY_SIMPLEX, 1.0, (255, 255, 255), 2)
        cv2.putText(frame, status, (20, 80),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 255, 255), 2)
        cv2.putText(frame, f"BLINK COUNT: {blink_count}", (20, 120),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 255, 255), 2)
        cv2.putText(frame, f"TH={BLINK_TH:.2f} cooldown={BLINK_COOLDOWN_SEC:.2f}s",
                    (20, 160), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (200, 200, 200), 2)

        cv2.imshow("core_only (MediaPipe Tasks + Blink)", frame)

        key = cv2.waitKey(1) & 0xFF
        if key == 27 or key == ord("q"):
            break

    cap.release()
    cv2.destroyAllWindows()

if __name__ == "__main__":
    main()
